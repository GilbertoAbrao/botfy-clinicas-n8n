---
phase: 26-validation-archive
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - .planning/phases/26-validation-archive/26-01-VALIDATION-REPORT.md
autonomous: true

must_haves:
  truths:
    - "All 10 migrated tools have correct node type (toolHttpRequest)"
    - "All tools are connected to AI Agent via ai_tool connection"
    - "All tools use Botfy Agent API credential for Bearer auth"
    - "All API endpoints return 200 for valid requests"
    - "All API endpoints return 401 for missing/invalid auth"
    - "All API endpoints return 400 for validation errors"
  artifacts:
    - path: ".planning/phases/26-validation-archive/26-01-VALIDATION-REPORT.md"
      provides: "Validation report with pass/fail status for each tool"
      contains: "VALIDATION REPORT"
  key_links:
    - from: "N8N workflow bPJamJhBcrVCKgBg"
      to: "toolHttpRequest nodes"
      via: "ai_tool connection"
      pattern: "type.*toolHttpRequest"
    - from: "toolHttpRequest nodes"
      to: "/api/agent/* endpoints"
      via: "HTTP requests with Bearer token"
      pattern: "Authorization.*Bearer"
---

<objective>
Validate all 10 migrated tools via static workflow inspection and API testing.

Purpose: Confirm the migration from toolWorkflow to toolHttpRequest is complete and all tools function correctly before archiving old sub-workflows.
Output: Validation report documenting pass/fail status for each tool with static checks and API tests.
</objective>

<execution_context>
@/Users/gilberto/.claude/get-shit-done/workflows/execute-plan.md
@/Users/gilberto/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/26-validation-archive/26-RESEARCH.md
@src/lib/agent/middleware.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Static validation of all 10 toolHttpRequest nodes via N8N MCP</name>
  <files>.planning/phases/26-validation-archive/26-01-VALIDATION-REPORT.md</files>
  <action>
Use N8N MCP to inspect the AI Agent workflow (ID: bPJamJhBcrVCKgBg) and validate each of the 10 migrated tools.

For each tool, verify:
1. Node exists with correct name
2. Node type is `@n8n/n8n-nodes-langchain.toolHttpRequest`
3. Node has ai_tool connection to AI Agent node
4. Node has httpHeaderAuth credential named "Botfy Agent API"
5. URL pattern matches expected endpoint
6. Required placeholders are defined

Tools to validate (name -> expected endpoint):
1. buscar_slots_disponiveis -> GET /api/agent/slots
2. buscar_agendamentos -> GET /api/agent/agendamentos
3. buscar_paciente -> GET /api/agent/paciente
4. status_pre_checkin -> GET /api/agent/pre-checkin/status
5. buscar_instrucoes -> GET /api/agent/instrucoes
6. criar_agendamento -> POST /api/agent/agendamentos
7. reagendar_agendamento -> PATCH /api/agent/agendamentos/{id}
8. cancelar_agendamento -> DELETE /api/agent/agendamentos/{id}
9. atualizar_dados_paciente -> PATCH /api/agent/paciente/{id}
10. processar_documento -> POST /api/agent/documentos/processar

Use mcp__n8n-mcp__n8n_get_workflow to get workflow JSON and parse nodes array.

Create validation report markdown file with table showing pass/fail for each check.
  </action>
  <verify>
Read the VALIDATION-REPORT.md file and confirm:
- All 10 tools have static validation results
- Each tool shows node type, connection, credential, and URL checks
- No FAIL entries in required checks
  </verify>
  <done>Static validation section of report shows PASS for all 10 tools on: node type, ai_tool connection, credential configuration, URL pattern.</done>
</task>

<task type="auto">
  <name>Task 2: API validation of all 10 endpoints with auth and error handling tests</name>
  <files>.planning/phases/26-validation-archive/26-01-VALIDATION-REPORT.md</files>
  <action>
Test each API endpoint using curl with the Bearer token from AGENT_API_KEY environment variable.

For each endpoint, test:
1. Valid request with correct params -> expect 200
2. Missing/invalid Authorization header -> expect 401
3. Missing required param (where applicable) -> expect 400

API endpoints and test cases:

1. GET /api/agent/slots?data=2026-01-27
   - Valid: 200 with slots array
   - No auth: 401
   - Missing data param: 400

2. GET /api/agent/agendamentos?telefone=11999999999
   - Valid: 200 with agendamentos array
   - No auth: 401

3. GET /api/agent/paciente?telefone=11999999999
   - Valid: 200 with paciente object or empty
   - No auth: 401

4. GET /api/agent/pre-checkin/status?agendamentoId=test-id
   - Valid: 200 (may return 404 for invalid ID)
   - No auth: 401

5. GET /api/agent/instrucoes
   - Valid: 200 with instrucoes array
   - No auth: 401

6. POST /api/agent/agendamentos (body validation only)
   - No auth: 401
   - Empty body: 400

7. PATCH /api/agent/agendamentos/test-id
   - No auth: 401
   - Missing dataHora: 400

8. DELETE /api/agent/agendamentos/test-id
   - No auth: 401
   - Missing motivo: 400

9. PATCH /api/agent/paciente/test-id
   - No auth: 401

10. POST /api/agent/documentos/processar
    - No auth: 401
    - Missing patientId: 400

Use the dev server URL (http://localhost:3051) or production URL if dev not available.
Load AGENT_API_KEY from .env.local or environment.

Append API validation results to the VALIDATION-REPORT.md file.
  </action>
  <verify>
Run: grep -c "API Validation" .planning/phases/26-validation-archive/26-01-VALIDATION-REPORT.md
Confirm API validation section exists with results for all 10 endpoints.
Check: grep "401" .planning/phases/26-validation-archive/26-01-VALIDATION-REPORT.md (should find auth test results)
  </verify>
  <done>API validation section shows: all 10 endpoints tested, auth validation works (401 on missing/invalid token), validation errors return 400 where applicable.</done>
</task>

<task type="auto">
  <name>Task 3: Create validation summary with overall status</name>
  <files>.planning/phases/26-validation-archive/26-01-VALIDATION-REPORT.md</files>
  <action>
Add summary section to VALIDATION-REPORT.md with:

1. Overall status: PASS/FAIL
2. Summary table with all 10 tools showing:
   - Tool name
   - Static checks (PASS/FAIL)
   - Auth test (PASS/FAIL)
   - Error handling test (PASS/FAIL)
   - Overall status

3. Ready for archive: YES/NO
   - Only YES if all tools PASS all checks

4. Notes section for any warnings or observations

Format the report to be human-readable and suitable for commit to git as verification documentation.

If any tool FAILs critical checks:
- Set overall status to FAIL
- Set ready for archive to NO
- Document specific failures for gap closure
  </action>
  <verify>
Read final VALIDATION-REPORT.md and confirm:
- Has Overall Status section
- Has summary table with all 10 tools
- Has Ready for Archive decision
- File is valid markdown
  </verify>
  <done>Validation report complete with overall status, summary table, and archive readiness decision. If all pass, report shows "Ready for Archive: YES".</done>
</task>

</tasks>

<verification>
After all tasks:
1. .planning/phases/26-validation-archive/26-01-VALIDATION-REPORT.md exists
2. Report contains static validation for 10 tools
3. Report contains API validation for 10 endpoints
4. Report contains summary with overall status
5. Overall status is PASS (or documented failures for gap closure)
</verification>

<success_criteria>
- All 10 toolHttpRequest nodes verified in N8N workflow
- All 10 API endpoints tested for auth and basic functionality
- Validation report created and committed
- Clear pass/fail status for each tool
- Archive readiness determined
</success_criteria>

<output>
After completion, create `.planning/phases/26-validation-archive/26-01-SUMMARY.md`
</output>
